---
title: "homework 5"
author: Purnima Sharma
date: "11/10/2020"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(rvest)
library(ggplot2)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,         
  out.width = "90%"      
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis", 
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d

set.seed(1)
```

## Problem 1

To look at the proportion of unsolved homicides in 50 major U.S. cities.

Read data.

```{r}
homicide_df =
  read_csv("homicide_data/homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved",
    )
  ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL")
```

Analyzing data.

```{r}
aggregate_df =
  homicide_df %>% 
    group_by(city_state) %>% 
    summarize(
      hom_total = n(),
      hom_unsolved = sum(resolved == "unsolved")
   )
```

Trying Prop test for a single city (Baltimore).

```{r}
prop.test(
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_unsolved),
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_total)) %>% 
  broom::tidy()
```

Using iteration to calculate for rest of the cities.

```{r}
results_df = 
  aggregate_df %>% 
    mutate(
      prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
      tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
    ) %>% 
    select(-prop_tests) %>% 
    unnest(tidy_tests) %>% 
    select(city_state, estimate, conf.low, conf.high)
```


Graphing resulting dataframe.

```{r}
results_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```


## Problem 2

### Longitudinal study analysis of 10 participants, with 8 weeks of observations.

Read data.

```{r}
path_df = 
  tibble(
    path = list.files("lda_data")
  ) %>% 
  mutate(
    path = str_c("lda_data/", path),
    data = map(.x = path, ~read_csv(.x))
    )
```

tidy the data.

```{r}
lda_df = 
   path_df %>% 
  mutate(path = str_replace(path, "\\lda_data/", "")) %>% 
  separate(path, into = c("arm", "id"), sep = "\\_") %>% 
  mutate(
    id = str_replace(id, "\\.csv", ""),
    arm = replace(arm, arm == "con", "control")
  ) %>% 
  select(id, everything()) %>% 
  unnest(data) %>% 
   pivot_longer(
     week_1:week_8,
     names_to = "week",
     names_prefix = "week_",
     values_to = "obs"
   )

lda_df
```

Spaghetti plot

```{r}
lda_df %>% 
    ggplot(
      aes(x = week, y = obs, color = arm, group = interaction(arm, id)),
      alpha = 0.3,) +
    geom_line() +
    ggtitle("Observations over time")
```

The graph indicates that on an average the values of observations were higher for subjects in the experimental group versus when in the control group. Also, the average trend in the experimental group showed increasing observation-values over the 8 weeks time period, versus more or less consistent values in the control arm.


## Problem 3

To explore power in a simple linear regression, using simulation.

Setting up the t-test function

```{r}
sim_mean_p = function(samp_size = 30, mu, sigma = 5) {
  
sim_data = 
  tibble(
      obs = rnorm(n = samp_size, mean = mu, sd = sigma)
  ) 

sim_result = 
  nest(sim_data, data = everything()) %>% 
  mutate(
  t_test = map(.x = data, ~t.test(x = .x, mu = 0, alternative = 'two.sided', paired = FALSE, conf.level = 0.95)),
  tidy_test = map(.x = t_test, ~broom::tidy(.x))
  ) 

return(sim_result)

}
```

Simulating data 5,000 times for each mean, using function

```{r}
simulation_results =   
  tibble(
    true_mean = c(0, 1, 2, 3, 4, 5, 6)
  ) %>% 
  mutate(
    output_lists = map(.x = true_mean, ~ rerun(5000,sim_mean_p(mu = .x))),  
     estimate_df = map(output_lists, bind_rows)
  ) %>% 
  select(-output_lists) %>%
  unnest(estimate_df)  
  
simulation_results =
simulation_results %>% 
  unnest(tidy_test)

simulation_results =
 simulation_results %>%  
  mutate(
    mu_hat = estimate,
    p_value = p.value
  ) %>% 
  select(true_mean, mu_hat, p_value)

head(simulation_results)
```

Plots

1. Power of the test

```{r}
simulation_results %>% 
  mutate(reject = ifelse(p_value < 0.05, 1, 0)) %>% 
  group_by(true_mean) %>% 
  summarize(
    prop_reject_null = mean(reject)) %>% 
  ggplot(aes(x = true_mean, y = prop_reject_null)) +
  geom_point() +
  geom_line(color = "purple") +
  labs(
    title = "Proportion of times null is rejected",
    x = "true value of the mean",
    y = "Power"
  )
```

The above plot of the proportion of times the false null was rejected, which is the power of the test, versus the true population mean shows that proportions of rejecting the null hypothesis of mean equal to zero increase as the true population mean increases, to the point where rejection is almost 100% as population mean reaches values of four and more. Thus the effect size, which is the magnitude of the difference between the null and true means, is directly proportional to the power of the test. Significant p-values at true mean equaling 5 and 6 account for close to 100% rejections of null hypothesis, and close to zero rejections at true mean equaling the null value of zero reinforce the direct relationship between the power of a test and the effect size.

2.  Mean of sampling distribution versus the true mean, and mean of sampling distribution with significant p-values versus the true mean

```{r}
simulation_results %>% 
  group_by(true_mean) %>% 
  summarize(
    mu_hat_avg = mean(mu_hat)) %>% 
  ggplot(aes(x = true_mean, y = mu_hat_avg)) +
  geom_point() +
  geom_line(color = "blue") +
  labs(
    title = "Mean of the sampling distribution versus the true mean",
    x = "true value of the mean",
    y = "Mean of sampling distribution"
  )
```


```{r}
simulation_results %>% 
   filter(p_value < 0.05) %>% 
   group_by(true_mean) %>% 
  summarize(
    mu_hat_avg = mean(mu_hat)) %>% 
  ggplot(aes(x = true_mean, y = mu_hat_avg)) +
  geom_point() +
  geom_line(color = "green") +
  labs(
    title = "Mean of the sampling distribution using sample means with significant p-values, versus the true mean",
    x = "true value of the mean",
    y = "Mean of sampling distribution with significant p-values"
  )
```

The outcomes of the graph indicate that the mean of the sample means appropriately reflect the true mean of their populations, given the sample size. The outcome is an approximately perfect linear relationship between the two sets of values. 

Meanwhile, when the average of sample means is calculated using only the estimates whose values reject the null hypothesis (indicated by the significant p-values), the outcome is no longer a true representative of the population means in many cases, more so where the true values are closer to the null value of zero.This makes sense as most p-values were insignificant when true means were closer to zero, and thus resulted in smaller sample-sizes and in turn to greater standard deviations of randomness of values, while most of the larger true values of the population means resulted in higher percentage of rejected null hypothesis outcomes, thus resulting in greater sample size and in turn greater accuracy of the true estimates. 

The graph below shows the comparison between the two on the same plot.

```{r}
plot_table1 = 
  simulation_results %>% 
    group_by(true_mean) %>% 
    summarize(
      mu_hat_avg1 = mean(mu_hat))
  
plot_table2 = 
  simulation_results %>% 
     filter(p_value < 0.05) %>% 
    group_by(true_mean) %>% 
    summarize(
      mu_hat_avg2 = mean(mu_hat))

plot_table = left_join(plot_table1, plot_table2, by = c("true_mean" = "true_mean")) 

plot_table %>% 
ggplot(aes(x = true_mean)) + 
  geom_point(aes(y = mu_hat_avg1)) +
  geom_line(aes(y = mu_hat_avg1), color = "darkred") + 
 geom_point(aes(y = mu_hat_avg2)) + 
  geom_line(aes(y = mu_hat_avg2), color = "steelblue", linetype = "twodash") +
  labs(
    title = "Mean of the sampling distribution versus the true mean",
    x = "true value of the mean",
    y = "Mean of sampling distribution",
    caption = "Average of Sampling mean: Red line, Sampling means with significant p-values: Blue line"
  ) 
```

